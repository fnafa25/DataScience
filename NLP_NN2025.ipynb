{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rabO6_Nj-q76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'study_hours': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'pass': [0, 0, 0, 1, 1, 1, 1, 1]\n",
        "})\n",
        "\n",
        "X = data[['study_hours']].values\n",
        "y = data['pass'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Initialize weights and biases\n",
        "weights = np.random.randn(1)\n",
        "bias = np.random.randn(1)\n",
        "\n",
        "# Define feedforward function\n",
        "def feedforward(X):\n",
        "    z = np.dot(X, weights) + bias\n",
        "    return sigmoid(z)\n"
      ],
      "metadata": {
        "id": "qYtUmLB9DBcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n"
      ],
      "metadata": {
        "id": "DrYtNAgVDVcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "for epoch in range(1000):\n",
        "    # Forward pass\n",
        "    y_pred = feedforward(X_train)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = binary_cross_entropy(y_train, y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    gradients = np.dot(X_train.T, (y_pred - y_train)) / y_train.size\n",
        "    weights -= learning_rate * gradients\n",
        "    bias -= learning_rate * np.mean(y_pred - y_train)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n"
      ],
      "metadata": {
        "id": "Ra0QU5K5DkIY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}